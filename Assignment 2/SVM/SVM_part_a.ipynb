{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'..')\n",
    "from data import read_svm_data\n",
    "from cvxopt import matrix, solvers, spmatrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 784), (20000,), (3974, 784), (3974,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels, training_images = read_svm_data(\"training\", r\"../../MNIST_ORG\", [2, 3, 8, 9])\n",
    "testing_labels, testing_images = read_svm_data(\"testing\", r\"../../MNIST_ORG\", [2, 3, 8, 9])\n",
    "\n",
    "training_images.shape, training_labels.shape, testing_images.shape, testing_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.astype(np.float32) / 255.0\n",
    "testing_images = testing_images.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "N = training_labels.shape[0]  # number of training samples\n",
    "d = training_images.shape[1]  # dimension of each sample\n",
    "labels_to_classify = [2, 3, 8, 9]\n",
    "classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = training_labels.shape[0]\n",
    "d = training_images.shape[1]\n",
    "\n",
    "Q_rows = []\n",
    "Q_cols = []\n",
    "Q_vals = []\n",
    "\n",
    "# identity for w part\n",
    "for i in range(d):\n",
    "    Q_rows.append(i)\n",
    "    Q_cols.append(i)\n",
    "    Q_vals.append(1.0)\n",
    "\n",
    "# ensuring that the slack variables' matrix is positive semi-definite (otherwise cvxopt raises an error)\n",
    "for i in range(N):\n",
    "    Q_rows.append(d + 1 + i)\n",
    "    Q_cols.append(d + 1 + i)\n",
    "    Q_vals.append(1e-6)\n",
    "\n",
    "# sparse Q matrix\n",
    "Q = spmatrix(Q_vals, Q_rows, Q_cols, (d + N + 1, d + N + 1), 'd')\n",
    "\n",
    "# p vector\n",
    "p = matrix([0.0] * (d + 1) + [C] * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for digit 2...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6215e+04  5.4711e+04  4e+05  5e+00  1e+03\n",
      " 1:  2.5185e+04 -2.8912e+04  7e+04  8e-01  2e+02\n",
      " 2:  1.1248e+04 -7.1832e+03  2e+04  2e-01  5e+01\n",
      " 3:  5.9229e+03 -2.5777e+03  1e+04  9e-02  2e+01\n",
      " 4:  3.5283e+03 -5.1084e+02  5e+03  4e-02  9e+00\n",
      " 5:  2.5430e+03  3.2893e+02  2e+03  2e-02  4e+00\n",
      " 6:  1.8199e+03  8.3451e+02  1e+03  6e-03  2e+00\n",
      " 7:  1.5973e+03  1.0083e+03  6e+02  2e-03  5e-01\n",
      " 8:  1.4723e+03  1.0768e+03  4e+02  1e-03  3e-01\n",
      " 9:  1.3881e+03  1.1217e+03  3e+02  5e-04  1e-01\n",
      "10:  1.3351e+03  1.1499e+03  2e+02  3e-04  7e-02\n",
      "11:  1.2837e+03  1.1773e+03  1e+02  9e-05  2e-02\n",
      "12:  1.2585e+03  1.1916e+03  7e+01  3e-05  9e-03\n",
      "13:  1.2398e+03  1.2043e+03  4e+01  1e-05  4e-03\n",
      "14:  1.2318e+03  1.2088e+03  2e+01  3e-06  8e-04\n",
      "15:  1.2247e+03  1.2147e+03  1e+01  1e-06  3e-04\n",
      "16:  1.2207e+03  1.2180e+03  3e+00  5e-08  1e-05\n",
      "17:  1.2197e+03  1.2190e+03  7e-01  1e-08  3e-06\n",
      "18:  1.2193e+03  1.2193e+03  4e-02  1e-10  3e-08\n",
      "19:  1.2193e+03  1.2193e+03  1e-03  4e-12  1e-09\n",
      "20:  1.2193e+03  1.2193e+03  2e-05  6e-14  3e-10\n",
      "Optimal solution found.\n",
      "Training classifier for digit 3...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5263e+04  6.4435e+04  5e+05  6e+00  1e+03\n",
      " 1:  3.2593e+04 -3.8413e+04  9e+04  8e-01  2e+02\n",
      " 2:  1.5710e+04 -9.2510e+03  3e+04  2e-01  6e+01\n",
      " 3:  9.0860e+03 -3.5167e+03  1e+04  1e-01  3e+01\n",
      " 4:  6.4863e+03 -1.3526e+03  9e+03  6e-02  2e+01\n",
      " 5:  4.7464e+03  9.0677e+01  5e+03  3e-02  8e+00\n",
      " 6:  3.2731e+03  1.0884e+03  2e+03  1e-02  3e+00\n",
      " 7:  2.7195e+03  1.4478e+03  1e+03  5e-03  1e+00\n",
      " 8:  2.4929e+03  1.5762e+03  1e+03  3e-03  8e-01\n",
      " 9:  2.3226e+03  1.6680e+03  7e+02  2e-03  4e-01\n",
      "10:  2.1789e+03  1.7376e+03  5e+02  6e-04  2e-01\n",
      "11:  2.0825e+03  1.7842e+03  3e+02  3e-04  8e-02\n",
      "12:  2.0100e+03  1.8189e+03  2e+02  9e-05  2e-02\n",
      "13:  1.9708e+03  1.8405e+03  1e+02  4e-05  1e-02\n",
      "14:  1.9335e+03  1.8643e+03  7e+01  1e-05  4e-03\n",
      "15:  1.9151e+03  1.8762e+03  4e+01  5e-06  1e-03\n",
      "16:  1.9068e+03  1.8821e+03  2e+01  2e-06  4e-04\n",
      "17:  1.8992e+03  1.8882e+03  1e+01  4e-07  1e-04\n",
      "18:  1.8951e+03  1.8917e+03  3e+00  1e-08  3e-06\n",
      "19:  1.8939e+03  1.8928e+03  1e+00  2e-09  6e-07\n",
      "20:  1.8935e+03  1.8932e+03  3e-01  3e-10  9e-08\n",
      "21:  1.8934e+03  1.8933e+03  1e-02  2e-12  4e-10\n",
      "22:  1.8933e+03  1.8933e+03  3e-04  4e-14  3e-10\n",
      "Optimal solution found.\n",
      "Training classifier for digit 8...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5036e+04  5.9625e+04  4e+05  5e+00  1e+03\n",
      " 1:  2.9162e+04 -3.3642e+04  8e+04  8e-01  2e+02\n",
      " 2:  1.4024e+04 -6.7726e+03  2e+04  2e-01  5e+01\n",
      " 3:  8.4046e+03 -1.9853e+03  1e+04  9e-02  2e+01\n",
      " 4:  5.8986e+03  1.3577e+02  6e+03  4e-02  9e+00\n",
      " 5:  4.2509e+03  1.3173e+03  3e+03  2e-02  4e+00\n",
      " 6:  3.4464e+03  1.7892e+03  2e+03  8e-03  2e+00\n",
      " 7:  3.1970e+03  1.9358e+03  1e+03  5e-03  1e+00\n",
      " 8:  2.8992e+03  2.0961e+03  8e+02  3e-03  6e-01\n",
      " 9:  2.7635e+03  2.1646e+03  6e+02  1e-03  3e-01\n",
      "10:  2.6255e+03  2.2297e+03  4e+02  6e-04  1e-01\n",
      "11:  2.5389e+03  2.2712e+03  3e+02  2e-04  5e-02\n",
      "12:  2.4682e+03  2.3104e+03  2e+02  8e-05  2e-02\n",
      "13:  2.4207e+03  2.3390e+03  8e+01  2e-05  4e-03\n",
      "14:  2.3972e+03  2.3558e+03  4e+01  6e-06  1e-03\n",
      "15:  2.3852e+03  2.3642e+03  2e+01  1e-06  3e-04\n",
      "16:  2.3775e+03  2.3706e+03  7e+00  2e-07  4e-05\n",
      "17:  2.3749e+03  2.3729e+03  2e+00  3e-15  2e-11\n",
      "18:  2.3740e+03  2.3738e+03  2e-01  3e-15  3e-11\n",
      "19:  2.3739e+03  2.3739e+03  2e-02  3e-15  8e-11\n",
      "20:  2.3739e+03  2.3739e+03  8e-04  3e-15  5e-10\n",
      "Optimal solution found.\n",
      "Training classifier for digit 9...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6684e+04  6.5724e+04  5e+05  6e+00  2e+03\n",
      " 1:  3.1070e+04 -5.0198e+04  1e+05  1e+00  3e+02\n",
      " 2:  1.6981e+04 -1.3378e+04  4e+04  3e-01  8e+01\n",
      " 3:  1.0323e+04 -7.1175e+03  2e+04  1e-01  4e+01\n",
      " 4:  6.7650e+03 -4.0132e+03  1e+04  8e-02  2e+01\n",
      " 5:  5.4512e+03 -2.8754e+03  9e+03  5e-02  2e+01\n",
      " 6:  3.9257e+03 -1.6144e+03  6e+03  3e-02  9e+00\n",
      " 7:  3.2889e+03 -1.0947e+03  5e+03  2e-02  7e+00\n",
      " 8:  2.5305e+03 -5.0458e+02  3e+03  1e-02  4e+00\n",
      " 9:  2.2026e+03 -2.2508e+02  3e+03  9e-03  3e+00\n",
      "10:  1.6794e+03  1.2561e+02  2e+03  5e-03  2e+00\n",
      "11:  1.3478e+03  3.4993e+02  1e+03  3e-03  8e-01\n",
      "12:  1.0854e+03  5.0836e+02  6e+02  1e-03  3e-01\n",
      "13:  9.9931e+02  5.5535e+02  5e+02  6e-04  2e-01\n",
      "14:  9.0709e+02  6.0111e+02  3e+02  3e-04  1e-01\n",
      "15:  8.5651e+02  6.2431e+02  2e+02  1e-04  4e-02\n",
      "16:  8.1348e+02  6.4597e+02  2e+02  8e-05  2e-02\n",
      "17:  7.6968e+02  6.6945e+02  1e+02  4e-05  1e-02\n",
      "18:  7.5399e+02  6.7610e+02  8e+01  2e-05  5e-03\n",
      "19:  7.2997e+02  6.9085e+02  4e+01  4e-06  1e-03\n",
      "20:  7.2231e+02  6.9465e+02  3e+01  2e-07  6e-05\n",
      "21:  7.1510e+02  7.0092e+02  1e+01  7e-08  2e-05\n",
      "22:  7.1193e+02  7.0352e+02  8e+00  6e-15  6e-12\n",
      "23:  7.0882e+02  7.0642e+02  2e+00  5e-15  1e-11\n",
      "24:  7.0781e+02  7.0737e+02  4e-01  6e-15  1e-11\n",
      "25:  7.0760e+02  7.0757e+02  3e-02  6e-15  2e-11\n",
      "26:  7.0758e+02  7.0758e+02  7e-04  7e-15  1e-10\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for label in labels_to_classify:\n",
    "    print(f\"Training classifier for digit {label}...\")\n",
    "    yn = np.where(training_labels == label, 1, -1)\n",
    "    \n",
    "    A_rows, A_cols, A_vals = [], [], []\n",
    "\n",
    "    # constructing sparse A matrix for the constraint y_i(w*x_i​ + b) >= 1 − e_i\n",
    "    # converted to −y_i(w*x_i + b) − e_i <= −1, which is Gx <= h form\n",
    "    for i in range(N):\n",
    "        # -y_i * x_i\n",
    "        for j in range(d):\n",
    "            if training_images[i, j] != 0:\n",
    "                A_rows.append(i)\n",
    "                A_cols.append(j)\n",
    "                A_vals.append(float(-yn[i] * training_images[i, j]))\n",
    "        # -y_i\n",
    "        A_rows.append(i)\n",
    "        A_cols.append(d)\n",
    "        A_vals.append(float(-yn[i]))\n",
    "        \n",
    "        # slack variable\n",
    "        A_rows.append(i)\n",
    "        A_cols.append(d + 1 + i)\n",
    "        A_vals.append(-1.0)\n",
    "\n",
    "    # constraint e_i >= 0\n",
    "    for i in range(N):\n",
    "        A_rows.append(N + i)\n",
    "        A_cols.append(d + 1 + i)\n",
    "        A_vals.append(-1.0)\n",
    "\n",
    "    A = spmatrix(A_vals, A_rows, A_cols, (N + N, d + N + 1))\n",
    "\n",
    "    # c vector\n",
    "    c = matrix([-1.0] * N + [0.0] * N)\n",
    "    \n",
    "    # solve\n",
    "    sol = solvers.qp(Q, p, A, c)\n",
    "\n",
    "    w = np.array(sol['x'][:d]).flatten()\n",
    "    b = sol['x'][d]\n",
    "\n",
    "    classifiers[label] = (w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, classifiers):\n",
    "    predictions = {label: np.dot(X, w) + b for label, (w, b) in classifiers.items()}\n",
    "    final_predictions = np.fromiter((max(predictions, key=lambda x: predictions[x][i]) for i in range(len(X))), dtype=int)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 95.93%\n",
      "Testing Accuracy: 94.64%\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(training_images, classifiers)\n",
    "mapped_labels = np.array([label if label in labels_to_classify else None for label in training_labels])\n",
    "correct_predictions = np.sum(predictions == mapped_labels)\n",
    "accuracy = correct_predictions / len(training_labels)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "predictions = predict(testing_images, classifiers)\n",
    "mapped_labels = np.array([label if label in labels_to_classify else None for label in testing_labels])\n",
    "correct_predictions = np.sum(predictions == mapped_labels)\n",
    "accuracy = correct_predictions / len(testing_labels)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
